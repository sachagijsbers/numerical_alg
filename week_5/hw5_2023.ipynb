{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19c262e-c3b6-44b3-9f2b-ced7e9a749e0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-06d3e5bf55c941ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Homework set 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27370c86-4723-45ba-b362-842cf7a0ea10",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-736ff6bc3e0d0696",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before you turn this problem in, make sure everything runs as expected (in the menubar, select Kernel â†’ Restart Kernel and Run All Cells...).\n",
    "\n",
    "Please **submit this Jupyter notebook through Canvas** no later than **Mon Dec. 4, 9:00**. **Submit the notebook file with your answers (as .ipynb file) and a pdf printout. The pdf version can be used by the teachers to provide feedback. A pdf version can be made using the save and export option in the Jupyter Lab file menu.**\n",
    "\n",
    "Homework is in **groups of two**, and you are expected to hand in original work. Work that is copied from another group will not be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea03b3f8-0634-4301-b993-2e01c6ca38ee",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b13bc5ed16bce8e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 0\n",
    "Write down the names + student ID of the people in your group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf8a06b-e442-4c9d-97fe-1b8fdbfe4020",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fd464f55ba436b1c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Loes Bijman 15211312\n",
    "\n",
    "Sacha Gijsbers 12798525"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50472bda-279b-416b-9c5b-6fc3b1ff814c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 1 (6 points)\n",
    "\n",
    "A bacterial population $P$ grows according to the geometric progression\n",
    "\n",
    "$$P_t = rP_{t-1}$$\n",
    "\n",
    "Where r is the growth rate. The following population counts $P_1 ,\\ldots, P_8$ (in billions) are observed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ff320c-517a-45da-99a8-ca87efc419a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array( [0.19, 0.36, 0.69, 1.3, 2.5, 4.7, 8.5, 14] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc3b80-e915-4854-a878-35d0ba645f80",
   "metadata": {},
   "source": [
    "# (a)\n",
    "Read chapter 6.6 on Nonlinear Least squares. Use the Gauss-Newton Method to fit the model function $f(t, x_1, x_2) = x_1\\!\\cdot x_2^t$ to the data. Find estimates for the initial population $P_0=x_1$ and the growth rate $r=x_2$. Implement the Gauss-Newton method yourself. You may use linear algebra functions from `scipy` and `numpy`. Plot the datapoints and the curve fitted to the data in a semilogarithmic plot.\n",
    "\n",
    "It is best if you define your function for Gauss-Newton separately from the definitions associated with the bacterial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c492fe88-c321-4b8c-9bd8-236f815b1369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  0.]\n",
      " [ 9.  2.]\n",
      " [27. 12.]\n",
      " [81. 54.]]\n",
      "[  -5.81  -17.64  -53.31 -160.7 ]\n",
      "[2, 3, array([1.95187008, 0.04823131]), array([0.00360294]), 2, array([102.02103482,   5.97565511]), array([1.95187008, 0.04823131]), array([0.00360294]), 2, array([102.02103482,   5.97565511]), array([1.95187008, 0.04823131]), array([0.00360294]), 2, array([102.02103482,   5.97565511]), array([1.95187008, 0.04823131]), array([0.00360294]), 2, array([102.02103482,   5.97565511]), array([1.95187008, 0.04823131]), array([0.00360294]), 2, array([102.02103482,   5.97565511]), array([1.95187008, 0.04823131]), array([0.00360294]), 2, array([102.02103482,   5.97565511]), array([1.95187008, 0.04823131]), array([0.00360294]), 2, array([102.02103482,   5.97565511]), array([1.95187008, 0.04823131]), array([0.00360294]), 2, array([102.02103482,   5.97565511]), array([1.95187008, 0.04823131]), array([0.00360294]), 2, array([102.02103482,   5.97565511]), array([1.95187008, 0.04823131]), array([0.00360294]), 2, array([102.02103482,   5.97565511])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wr/_f23fm512gg3qhxthyg30lvc0000gn/T/ipykernel_18402/3005658341.py:28: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  s = np.linalg.lstsq(Jacobian(t_data,x),-residual(t_data,y_data,function,x))\n"
     ]
    }
   ],
   "source": [
    "# define Gauss-Newton here\n",
    "\n",
    "def fit_function(t, x0):\n",
    "    '''function used to fit to the data'''\n",
    "    return x0[0] * x0[1]**t\n",
    "\n",
    "def dfdx1(t_data,x0):\n",
    "    '''partial derivative over x1'''\n",
    "    return x0[1]**t_data\n",
    "\n",
    "def dfdx2(t_data,x0):\n",
    "    '''partial derivative over x2'''\n",
    "    return (t_data-1) * x0[0] * x0[1]**(t_data-2)\n",
    "\n",
    "def Jacobian(t_data,x0):\n",
    "    '''returns the Jacobian matrix given the partial derivatives over x1 and x2'''\n",
    "    return np.column_stack((dfdx1(t_data,x0),dfdx2(t_data,x0)))\n",
    "\n",
    "def residual(t_data,y_data,function,x0):\n",
    "    res = []\n",
    "    for index,t in enumerate(t_data):\n",
    "        res.append(y_data[index] - function(t, x0))\n",
    "    return np.array(res)\n",
    "\n",
    "def Gauss_Newton(t_data,y_data,function,x0,max_iterations):\n",
    "    x = x0\n",
    "    for _ in range(max_iterations):\n",
    "        s = np.linalg.lstsq(Jacobian(t_data,x),-residual(t_data,y_data,function,x))\n",
    "        x += s\n",
    "    return x\n",
    "\n",
    "x0 = [2,3]\n",
    "t_data = np.array([1.0,2,3,4])\n",
    "y_data = np.array([0.19, 0.36, 0.69, 1.3])\n",
    "max_iterations = 10\n",
    "\n",
    "print(Jacobian(t_data,x0)) \n",
    "print(residual(t_data,y_data,fit_function,x0))\n",
    "print(Gauss_Newton(t_data, y_data, fit_function, x0, max_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574b3c1-5a64-47d4-b0d4-45cd87216829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make definitions for bacterial model and run Gauss-Newton here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56e7014-dda8-4984-8fce-d0a5a16d046f",
   "metadata": {},
   "source": [
    "# (b)\n",
    "Let $f$ be a vector valued function $f = [ f_1, \\ldots, f_m ]^T$. In weighted least squares one aims to minimize the objective function\n",
    "$$\n",
    "  \\phi(x) = \\frac{1}{2} \\sum_{i=1}^m W_{ii} ( y_i - f_i(x)) ^2 , \\qquad\n",
    "  W_{ii} = \\frac{1}{\\sigma_i^2} , \n",
    "$$\n",
    "where $\\sigma_i$ is an estimate of the standard deviation in the data point $y_i$. This is equivalent to the standard least squares problem \n",
    "$$\n",
    "\\min_x \\frac{1}{2} \\| Y - F(x) \\|_2^2\n",
    "$$\n",
    "with $F_i(x) = \\frac{1}{\\sigma_i} f(x)$  , $Y_i = \\frac{1}{\\sigma_i} y_i$. Assume that for each data point $y_i$ in the list above, the estimate for the standard deviation is given by\n",
    "$$\n",
    "  \\sigma_i = 0.05 y_i .\n",
    "$$ \n",
    "Perform a weighted least squares fit to obtain estimates for $P_0$ and $r$. \n",
    "\n",
    "Plot the datapoints and the curve fitted to the data again in a semilogarithmic plot.\n",
    "\n",
    "Compare the residuals, i.e. the values of $y_i - f_i(x)$) obtained in (a) and (b), and discuss the differences between the results of the weighted and the unweighted optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3a80a-d0f0-4b9f-8004-95b4e8ba7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0cbd35-09de-449a-80d5-c4da70b394bc",
   "metadata": {},
   "source": [
    "# Exercise 2 (3 points)\n",
    "A triangle has been measured. The measurements, a vector $x \\in \\mathbb{R}^6$, are as follows:\n",
    "$$\\begin{array}{c|c|c|c|c|c}\n",
    "x_1 = \\alpha \n",
    "& x_2 = \\beta\n",
    "& x_3 = \\gamma\n",
    "& x_4 = a\n",
    "& x_5 = b\n",
    "& x_6 = c \\\\ \\hline\n",
    "67.5^{\\large\\circ}\n",
    "& 52^{\\large\\circ}\n",
    "& 60^{\\large\\circ}\n",
    "& 172 \\text{m}\n",
    "& 146 \\text{m}\n",
    "& 165 \\text{m}\n",
    "\\end{array} .\n",
    "$$\n",
    "Here $\\alpha, \\beta, \\gamma$ are the angles opposite the sides with length $a$, $b$, $c$, respectively.\n",
    "The measurements $x$ have errors. We would like to correct them so that the new values $\\tilde{x} = x + h$ are consistent quantities of a triangle. The have to satisfy:\n",
    "$$ \\tag{*}\n",
    "\\begin{array}{ccc}\n",
    "\\text{Sum of angles:} \n",
    "& \\;\\;\\;\\;\\; & \n",
    "\\tilde{x}_1 + \\tilde{x}_2 + \\tilde{x}_3 = 180^{\\large\\circ}\n",
    "\\\\\n",
    "\\text{Sine theorem:}\n",
    "&&\n",
    "\\tilde{x}_4 \\sin(\\tilde{x}_2) - \\tilde{x}_5 \\sin(\\tilde{x}_1) = 0\n",
    "\\\\\n",
    "&&\n",
    "\\tilde{x}_5 \\sin(\\tilde{x}_3) - \\tilde{x}_6 \\sin(\\tilde{x}_2) = 0 .\n",
    "\\end{array}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c5137-9cf9-4f1e-9376-a2ca28ab2dd9",
   "metadata": {},
   "source": [
    "## (a)\n",
    "Solve the constrained least squares problem $\\min_x \\| h \\|_2^2$ subject to the constraints given by (*).\n",
    "\n",
    "Use `scipy.optimize.minimize`.\n",
    "\n",
    "Hint: Don't forget to work in radians!\n",
    "\n",
    "Check that for the new values also e.g. the cosine theorem $c^2 = a^2 + b^2 - 2 ab \\cos(\\gamma)$ holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd180378-9e14-4e45-ac0d-4dedd620303f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb8f5e56-d57b-44f6-878f-d8d420d4d0a2",
   "metadata": {},
   "source": [
    "## (b)\n",
    "You will notice that the corrections will be made mainly to the angles and much less to the lengths of the sides of the triangle. This is because the measurements have not the same absolute errors. While the error in last digit of the sides is about 1, the errors in radians of the angles are about 0.01. Repeat your computation by taking in account with appropriate weighting the difference in measurement errors. Minimize not simply $\\| h \\|_2^2$ but\n",
    "$$\n",
    "  \\left\\| \\begin{bmatrix} 100 h_1 \\\\ 100 h_2 \\\\ 100 h_3 \\\\ h_4 \\\\ h_5 \\\\ h_6 \\end{bmatrix} \\right\\|_2^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc292e7-2304-4676-8d39-25f5a33246f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
