{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca33f70-0324-4594-8998-08352cc65c9d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-06d3e5bf55c941ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a085ff85-5f47-4d16-b0bb-5adf07e3e503",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-736ff6bc3e0d0696",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please **submit this Jupyter notebook through Canvas** no later than **Mon Nov. 13, 9:00**. **Submit the notebook file with your answers (as .ipynb file) and a pdf printout. The pdf version can be used by the teachers to provide feedback. A pdf version can be made using the save and export option in the Jupyter Lab file menu.**\n",
    "\n",
    "Homework is in **groups of two**, and you are expected to hand in original work. Work that is copied from another group will not be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc44ed9-3b17-4f38-94fe-0f4d709ed1d6",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b13bc5ed16bce8e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 0\n",
    "Write down the names + student ID of the people in your group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3075893-8ccd-4cab-b8a0-741c30648ebe",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fd464f55ba436b1c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Loes Bijman 15211312\n",
    "\n",
    "Sacha Gijsbers 12798525"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d93788-1857-48f1-bfff-8cf004cf1a5d",
   "metadata": {},
   "source": [
    "## Importing packages\n",
    "Execute the following statement to import the packages `numpy`, `math` and `scipy.sparse`. If additional packages are needed, import them yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c56160e-301a-4888-b439-a45bc02b8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy\n",
    "from fractions import Fraction\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967cec69-1602-4c3c-9bff-871eabca2c8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sparse matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b9158-f983-4dd6-a478-2dd0456961ca",
   "metadata": {},
   "source": [
    "A matrix is called sparse if only a small fraction of the entries is nonzero. For such matrices, special data formats exist. `scipy.sparse` is the scipy package that implements such data formats and provides functionality such as the LU decomposition (in the subpackage `scipy.sparse.linalg`).\n",
    "\n",
    "As an example, we create the matrix \n",
    "$$\\begin{bmatrix} 1 & 0 & 2 & 0\\\\ \n",
    "0 & 3 & 0 & 0 \\\\\n",
    "0 & 0 & 4 & 5 \\\\\n",
    "0 & 0 & 0 & 6 \n",
    "\\end{bmatrix}$$ in the so called compressed sparse row (CSR) format. As you can see, the arrays `row`, `col`, `data` contain the row and column coordinate and the value of each nonzero element respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9090c65-724c-4bfc-a19c-85cd7314ca06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 2. 0.]\n",
      " [0. 3. 0. 0.]\n",
      " [0. 0. 4. 5.]\n",
      " [0. 0. 0. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# a sparse matrix with 6 nonzero entries\n",
    "row = np.array([0, 0, 1, 2, 2, 3])\n",
    "col = np.array([0, 2, 1, 2, 3, 3])\n",
    "data = np.array([1.0, 2, 3, 4, 5, 6])\n",
    "sparseA = sp.csr_array((data, (row, col)), shape=(4, 4))\n",
    "\n",
    "# convert to a dense matrix. This allows us to print to screen in regular formatting\n",
    "denseA = sparseA.toarray()\n",
    "print(denseA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcb2618-8ec2-4cd2-86b3-786946719c20",
   "metadata": {},
   "source": [
    "For sparse matrices, a sparse data format is much more efficient in terms of storage than the standard array format. Because of this efficient storage, very large matrices of size $n \\times n$ with $n = 10^7$ or more can be stored in RAM for performing computations on regular computers. Often the number of nonzero elements per row is quite small, such as 10's or 100's nonzero elements per row. In a regular, dense format, such matrices would require a supercomputer or could not be stored.\n",
    "\n",
    "In the second exercise you have to use the package `scipy.sparse`, please look up the functions you need (or ask during class)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a0788-7ac3-41e5-afbb-2957220c6a2a",
   "metadata": {},
   "source": [
    "# Heath computer exercise 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e9755-32ad-42e6-bd4a-9066e36cf4f9",
   "metadata": {},
   "source": [
    "## (a)\n",
    "Show that the matrix\n",
    "$$ A = \\begin{bmatrix} \n",
    "0.1 & 0.2 & 0.3 \\\\\n",
    "0.4 & 0.5 & 0.6 \\\\\n",
    "0.7 & 0.8 & 0.9\n",
    "\\end{bmatrix}.$$\n",
    "is singular. Describe the set of solutions to the system $A x = b$ if\n",
    "$$ b = \\begin{bmatrix} 0.1 \\\\ 0.3 \\\\ 0.5 \\end{bmatrix}. $$\n",
    "(N.B. this is a pen-and-paper question.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044019bb-6f29-446c-8cf4-a65c7033cf6c",
   "metadata": {},
   "source": [
    "--------------------------------------------------\n",
    "We can see that\n",
    "\n",
    "$\\rm{det}(A) = 0.1\\cdot(0.5\\cdot 0.9 - 0.6\\cdot 0.8) - 0.2(0.4\\cdot 0.9 - 0.6\\cdot 0.7) + 0.3\\cdot(0.4\\cdot 0.8 - 0.5\\cdot 0.7) = 0$\n",
    "\n",
    "Therefore matrix $A$ is singular.\n",
    "\n",
    "Since $A$ is singular, we know there is a nonzero vector $\\textbf{z}$ such that $A\\textbf{z} = \\textbf{0}$. Thus, if $\\textbf{x}$ is a solution to $A\\textbf{x} = \\textbf{b}$, this means $\\textbf{x} + \\gamma \\cdot \\textbf{z}$ is also a solution, for any $\\gamma \\in \\mathbb{R}$.\n",
    "\n",
    "LU decomposition for matrix $A$ gives $L = \\begin{bmatrix} 1 & 0 & 0 \\\\ 4 & 1 & 0 \\\\ 7 & -2 & 1 \\end{bmatrix}$ and $U = \\begin{bmatrix} 0.1 & 0.2 & 0.3 \\\\ 0 & -0.3 & -0.6 \\\\ 0 & 0 & 0 \\end{bmatrix}$. Using these matrices and performing forward and backward substitution, we find $\\textbf{z} = \\begin{bmatrix} 1 \\\\ -2 \\\\ 1 \\end{bmatrix}$ and $\\textbf{x} = \\begin{bmatrix} 1/3 \\\\ 1/3 \\\\ 0 \\end{bmatrix}$. \n",
    "\n",
    "Therefore the general solution is $x = \\begin{bmatrix} 1/3 \\\\ 1/3 \\\\ 0 \\end{bmatrix} + \\gamma \\begin{bmatrix} 1 \\\\ -2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1/3 + \\gamma \\\\ 1/3 - 2\\gamma \\\\ \\gamma \\end{bmatrix}$ for all $\\gamma \\in \\mathbb{R}$ (or in $\\mathbb{C}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14074eea-48d7-49e6-81b1-5fadeaeec111",
   "metadata": {},
   "source": [
    "## (b)\n",
    "If we were to use Gaussian elimination with partial pivoting to solve this system using exact arithmetic, at what point would the process fail?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aa07a1-da53-4f43-bad8-8be6c55e0c39",
   "metadata": {},
   "source": [
    "In the context of LU (Lower-Upper) factorization, which is used for solving linear systems of equations, it is assumed that the original matrix A can be decomposed into two matrices, L and U, such that A = LU. L is a lower triangular matrix, all entries above the main diagonal are zero. U is an upper triangular matrix, all entries below the main diagonal are zero.\n",
    "\n",
    " In exact arithmetic, LU factorization, like Gaussian elimination with partial pivoting, is a numerically stable method for solving systems of linear equations. However, if the original matrix A is singular, it can indeed lead to a zero on the diagonal of the upper triangular factor U, hich may result in a failure during the back-substitution step due to division by zero when solving for the variables in the system of equations. The LU factorization would still work but solution process would fail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c1ae38-f504-47eb-a1d6-eec193e32878",
   "metadata": {},
   "source": [
    "## (c)\n",
    "Because some of the entries of $A$ are not exactly representable in a binary floating point system, the matrix is no longer exactly singular when entered into a computer; thus, solving the system by Gaussian elimination will not necessarily fail. Solve this system on a computer using a library routine for Gaussian elimination. Compare the computed solution with your description of the solution set in part (a). What is the estimated value for $\\text{cond}(A)$? How many digits of accuracy in the solution would this lead you to expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6808a3-aecd-4ebe-aa79-5ddcbff09c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      " [[0.1 0.2 0.3]\n",
      " [0.4 0.5 0.6]\n",
      " [0.7 0.8 0.9]]\n",
      "b: [0.1 0.3 0.5]\n",
      "Solution set x: [ 0.16145833  0.67708333 -0.171875  ]\n"
     ]
    }
   ],
   "source": [
    "# sparse matrix A\n",
    "row = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])\n",
    "col = np.array([0, 1, 2, 0, 1, 2, 0, 1, 2])\n",
    "data = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "sparseA = sp.csr_array((data, (row, col)), shape=(3, 3))\n",
    "\n",
    "# convert to dense matrix\n",
    "A = sparseA.toarray()\n",
    "print(f\"Matrix A:\\n {A}\")\n",
    "\n",
    "b = np.array([0.1, 0.3, 0.5])\n",
    "print(f\"b: {b}\")\n",
    "\n",
    "# Perform Gaussian elimination with partial pivoting\n",
    "lu, piv = scipy.linalg.lu_factor(A)\n",
    "x = scipy.linalg.lu_solve((lu, piv), b)\n",
    "\n",
    "print(f\"Solution set x: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bade5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution from 2.1(a) with gamma = -0.171875: [ 0.16145833  0.67708333 -0.171875  ]\n",
      "Computed solution set: [ 0.16145833  0.67708333 -0.171875  ]\n"
     ]
    }
   ],
   "source": [
    "# Comparison of computed solution with calculation of 2.1(a)\n",
    "\n",
    "gamma = x[2] # using vectors from 2.1(a)\n",
    "x_1 = 1/3 + gamma\n",
    "x_2 = 1/3 - 2*gamma\n",
    "x_3 = gamma\n",
    "\n",
    "solution = np.array([x_1,x_2,x_3])\n",
    "\n",
    "print(f\"Solution from 2.1(a) with gamma = {gamma}: {solution}\")\n",
    "print(f\"Computed solution set: {x}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4318078",
   "metadata": {},
   "source": [
    "We can see that the solution found by the computer fits the general solution as found in 2.1(a) for $\\gamma = -0.171875$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6864de8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number of A with infinity norm: 8.64691128455135e+16\n",
      "cond(A)*machine_epsilon = 17.2938225691027\n",
      "log(cond(A)) = 16.93686100323057\n"
     ]
    }
   ],
   "source": [
    "condA = np.linalg.cond(A, p = np.inf)\n",
    "print(\"Condition number of A with infinity norm:\", condA)\n",
    "print(f\"cond(A)*machine_epsilon = {condA * 2*10**(-16)}\")\n",
    "print(f\"log(cond(A)) = {math.log(condA,10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32537b21-ef0e-4d21-83ec-630d7c6ef4ac",
   "metadata": {},
   "source": [
    "From Heath, we know that $\\frac{||\\textbf{\\^{x}}-\\textbf{x}||}{||\\textbf{x}||}\\lessapprox \\rm{cond}(A) \\epsilon_{\\rm{mach}}$. For double precision we have $\\epsilon_{\\rm{mach}} \\approx 2\\cdot 10^{-16}$. In our case, we obtain $\\frac{||\\textbf{\\^{x}}-\\textbf{x}||}{||\\textbf{x}||}\\lessapprox 8.6469 \\cdot 10^{16} \\cdot 2\\cdot 10^{-16} \\approx 17.29$. Furthermore, we can see that $\\rm{log}_{10}(\\rm{cond}(A)) \\approx \\rm{log}_{10}(8.6469 \\cdot 10^{16}) \\approx 16.9$ decimal digits of accuracy are lost relative to the accuracy of the input. Therefore we expect no correct digits in the solution unless the input data is accurate to more than 17 digits. Since only 16 digits can be accurately stored, the solution has lost all accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c99b9d-1ab5-49ae-9fa9-805bb984e4a5",
   "metadata": {},
   "source": [
    "# Heath computer exercise 2.17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad5ecf6-4902-4e39-af7c-20fae6a41eb5",
   "metadata": {},
   "source": [
    "Consider a horizontal cantilevered beam that is clamped at one end but free along the remainder of its length. A discrete model of the forces on the beam yields a system of linear equations $A x = b$, where the $n \\times n$ matrix $A$ has the banded form\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    " 9 & -4     &  1 &  0 & \\ldots & \\ldots & 0 \\\\\n",
    "-4 &  6     & -4 &  1 & \\ddots && \\vdots \\\\\n",
    " 1 & -4     &  6 & -4 &  1 & \\ddots & \\vdots \\\\\n",
    " 0 & \\ddots & \\ddots & \\ddots & \\ddots & \\ddots & 0 \\\\\n",
    " \\vdots & \\ddots & 1 & -4 &  6 & -4 &  1 \\\\ \n",
    " \\vdots && \\ddots    &  1 & -4 &  5 & -2 \\\\\n",
    " 0 & \\ldots & \\ldots & 0 & 1 & -2 & 1 \n",
    "\\end{bmatrix}, $$\n",
    "the $n$-vector $b$ is the known load on the bar (including its own weight), and the $n$-vector $x$ represents the resulting deflection of the bar that is to be determined. We will take the bar to be uniformly loaded, with $b_i = 1/n^4$ for each component of the load vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3221df-1706-4536-9d13-900af379a450",
   "metadata": {},
   "source": [
    "## (a)\n",
    "Make a python function that creates the matrix $A$ given the size $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f1d53a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9. -4.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-4.  6. -4.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1. -4.  6. -4.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1. -4.  6. -4.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -4.  6. -4.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -4.  6. -4.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1. -4.  6. -4.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1. -4.  6. -4.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1. -4.  6. -4.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1. -4.  6. -4.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1. -4.  6. -4.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -4.  6. -4.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -4.  6. -4.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -4.  6. -4.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -4.  5. -2.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -2.  1.]]\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "n = 16\n",
    "\n",
    "def create_beam_matrix_A(n):\n",
    "    b = np.ones(n)\n",
    "    A = scipy.sparse.diags([b, -4 * b, 6 * b, -4 * b, b], [-2, -1, 0, 1, 2], (n, n), format='csc')\n",
    "    A[0, 0] = 9\n",
    "    A[n - 2, n - 2] = 5\n",
    "    A[n - 1, n - 1] = 1\n",
    "    A[n - 1, n - 2] = -2\n",
    "    A[n - 2, n - 1] = -2\n",
    "\n",
    "    A_dense = A.toarray()\n",
    "\n",
    "    return A_dense\n",
    "\n",
    "A_dense = create_beam_matrix_A(n)\n",
    "print(A_dense)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7511aa-c209-4803-96a4-6743b5f52626",
   "metadata": {},
   "source": [
    "## (b)\n",
    "\n",
    "Solve this linear system using both a standard library routine for dense linear systems and a library routine designed for sparse linear systems. Take $n=100$ and $n=1000$. How do the two routines compare in the time required to compute the solution? And in the memory occupied by the LU decomposition? (Hint: as part of this assignment, look for the number of nonzero elements in the matrices $L$ and $U$ of the sparse LU decomposition.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9abb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "b = np.full(n, 1/(n^4))\n",
    "\n",
    "def time_dense_sparse(n,b):\n",
    "    A_dense = create_beam_matrix_A(n)\n",
    "    A_sparse = scipy.sparse.csr_matrix(create_beam_matrix_A(n))\n",
    "\n",
    "    start_dense = time.time()\n",
    "    lu_dense, piv_dense = scipy.linalg.lu_factor(A_dense)\n",
    "    x_dense = scipy.linalg.lu_solve((lu_dense, piv_dense), b)\n",
    "    end_dense = time.time()\n",
    "    time_dense = end_dense-start_dense\n",
    "\n",
    "    start_sparse = time.time()\n",
    "    lu_sparse = scipy.sparse.linalg.splu(A_sparse)\n",
    "    x_sparse = lu_sparse.solve(b)\n",
    "    end_sparse = time.time()\n",
    "    time_sparse = end_sparse-start_sparse\n",
    "    \n",
    "    return time_dense, time_sparse, lu_dense, lu_sparse, x_dense, x_sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e2da1b5-74b5-4490-b590-9604040c8aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loesbijman/anaconda3/envs/my-env/lib/python3.12/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:412: SparseEfficiencyWarning: splu converted its input to CSC format\n",
      "  warn('splu converted its input to CSC format', SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 100 (100 runs): dense average running time = 0.001464402675628662 seconds with std 0.0030169513626817543\n",
      "n = 100 (100 runs): sparse average running time = 0.0006986618041992188 seconds with std 0.0006130344464349809\n",
      "For n = 100, sparse is 0.0007657408714294433 seconds faster than dense\n",
      "---------------------------------------------------\n",
      "n = 100 (100 runs): dense memory occupation: 10000 elements and size 80128\n",
      "n = 100 (100 runs): sparse memory occupation: 691 elements and size 96\n",
      "---------------------------------------------------\n",
      "n = 1000 (100 runs): dense average running time = 0.020349955558776854 seconds with std 0.0013924381911442853\n",
      "n = 1000 (100 runs): sparse average running time = 0.001174635887145996 seconds with std 6.013545741531516e-05\n",
      "For n = 1000, sparse is 0.019175319671630858 seconds faster than dense\n",
      "---------------------------------------------------\n",
      "n = 1000 (100 runs): dense memory occupation: 1000000 elements and size 8000128\n",
      "n = 1000 (100 runs): sparse memory occupation: 6990 elements and size 96\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "runs = 100\n",
    "n_list = [100, 1000]\n",
    "for n in n_list:\n",
    "    all_time_dense, all_time_sparse = [],[]\n",
    "    all_nonzero_dense, all_nonzero_sparse = [], []\n",
    "    for _ in range(runs):\n",
    "        time_dense, time_sparse, lu_dense, lu_sparse, _, _ = time_dense_sparse(n,b)\n",
    "        all_time_dense.append(time_dense)\n",
    "        all_time_sparse.append(time_sparse)\n",
    "\n",
    "        num_elements_dense = n*n\n",
    "        size_dense = sys.getsizeof(lu_dense)\n",
    "\n",
    "        num_elements_sparse = (lu_sparse.L != 0).sum() + (lu_sparse.U != 0).sum()\n",
    "        size_sparse = sys.getsizeof(lu_sparse.L != 0) + sys.getsizeof(lu_sparse.U != 0)\n",
    "\n",
    "    mean_time_dense = np.mean(all_time_dense)\n",
    "    std_time_dense = np.std(all_time_dense)\n",
    "\n",
    "    mean_time_sparse = np.mean(all_time_sparse)\n",
    "    std_time_sparse = np.std(all_time_sparse)\n",
    "\n",
    "    print(f\"n = {n} ({runs} runs): dense average running time = {mean_time_dense} seconds with std {std_time_dense}\")\n",
    "    print(f\"n = {n} ({runs} runs): sparse average running time = {mean_time_sparse} seconds with std {std_time_sparse}\")\n",
    "\n",
    "    print(f\"For n = {n}, sparse is {mean_time_dense - mean_time_sparse} seconds faster than dense\")\n",
    "    print('---------------------------------------------------')\n",
    "\n",
    "    print(f\"n = {n} ({runs} runs): dense memory occupation: {num_elements_dense} elements and size {size_dense}\")\n",
    "    print(f\"n = {n} ({runs} runs): sparse memory occupation: {num_elements_sparse} elements and size {size_sparse}\")\n",
    "\n",
    "    print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9decc62c-feb5-4afb-bfba-0b8a19af5be3",
   "metadata": {},
   "source": [
    "We can see that the method for sparse LU decomposition is faster than the method for dense LU decomposition. When considering size $n$ of the matrix, LU decomposition is slower for both the dense and sparse method. The difference between the two methods is larger when $n$ is larger. We can see that the running time for LU decomposition with a dense matrix increases more than the running time for the sparse method.\n",
    "\n",
    "When looking at the memory occupied by the LU decompositions, we can see that the dense LU decomposition uses approximately 80000 bytes more then then the ssparse LU decomposition for $n = 100$. For $n = 1000$ the memory occupied by the sparse LU decomposition stays the same, whereas the memory occupied by the dense LU decomposition increases with a factor of 10. Since the dense matrix method stores the zero-values explicitly in all matrices, this method uses much more memory. This is also why the memory occupied by the sparse LU decomposition does not change with a bigger n, as with a bigger n more zero values are added to the matrix, while the non zero values stay the same, as they are not stored in the sparse LU decomposition, the same amount of memory is occupied for both values of $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebb2590-2f08-4362-aef6-f334eedbf306",
   "metadata": {},
   "source": [
    "## (c)\n",
    "For $n=100$, what is the condition number? What accuracy do you expect based on the condition number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d71e4897-2b95-44de-88a0-029c89a24609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number of A dense with infinity norm: 200666800.074768\n",
      "cond(A)*machine_epsilon = 4.01333600149536e-08\n",
      "log(cond(A)) = 8.302475525267644\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "A_dense = create_beam_matrix_A(n)\n",
    "\n",
    "condA_dense = np.linalg.cond(A_dense, p = np.inf)\n",
    "print(\"Condition number of A dense with infinity norm:\", condA_dense)\n",
    "print(f\"cond(A)*machine_epsilon = {condA_dense * 2*10**(-16)}\")\n",
    "print(f\"log(cond(A)) = {math.log(condA_dense,10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f316041-7f14-48dd-a458-3a01fe87daa3",
   "metadata": {},
   "source": [
    "For $n = 100$ we obtain $\\rm{cond}(A) \\approx 200666800.0746656$. The relative error in the approximate solution $\\textbf{\\^{x}}$ is therefore approximately bounded by $\\rm{cond}(A) \\epsilon_{\\rm{mach}} \\approx 4.0133 \\cdot 10^{-8}$. Therefore we expect to lose about $\\rm{log}_{10}(\\rm{cond}(A)) \\approx \\rm{log}_{10}(200666800.0746656) \\approx 8.3$ digits of accuracy relative to the accuracy of the input. Thus we expect no correct digits unless the input data and working memory are accurate to more than 8 decimal digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a94aca-a8cc-407c-9212-3b09e9bd850e",
   "metadata": {},
   "source": [
    "## (d)\n",
    "How well do the answers of (b) agree with each other (make an appropriate quantitative comparison)?\n",
    "\n",
    "Should we be worried about the fact that the two answers are different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3087de8-ee2b-45f1-a26c-06c747842835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative residual for dense method: 4.3991116791007416e-11\n",
      "relative residual for sparse method:4.7239361960273103e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loesbijman/anaconda3/envs/my-env/lib/python3.12/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:412: SparseEfficiencyWarning: splu converted its input to CSC format\n",
      "  warn('splu converted its input to CSC format', SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "_,_,_,_,x_dense, x_sparse = time_dense_sparse(100,b)\n",
    "\n",
    "# print(x_dense - x_sparse)\n",
    "\n",
    "def relative_residual(x_hat,A,b):\n",
    "    r = b-A.dot(x_hat)\n",
    "    relative_res = np.linalg.norm(r)/(np.linalg.norm(A)*np.linalg.norm(b))\n",
    "    return relative_res\n",
    "\n",
    "print(f\"relative residual for dense method: {relative_residual(x_dense,A_dense,b)}\")\n",
    "print(f\"relative residual for sparse method:{relative_residual(x_sparse,A_dense,b)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02317207-3944-4be0-a8e6-29d81d007b00",
   "metadata": {},
   "source": [
    "your answer (text) here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
